{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDA 2019 Kaggle Data Competition\n",
    "For the Data competition the task was to build a recommender system using information from a movie rating database. The training data was composed of user's ratings of different movies and information on the movies (genre, visual features, release year, tags and title). The objective of the system was to recommend to each user in the test set their top 10 favorite movies. \n",
    "The algorithm I decided to use for this assignment was SVD. SVD stands for Singular Value Decomposition which works using matrix factorization. Matrix factorization breaks down one matrix into the product of multiple matrices. Although there are many ways to do matrix factorization, SVD is quite powerful when used for recommendations. It decomposes a matrix into two unitary matrices and a diagonal matrix.\n",
    "\n",
    "                                               R=UΣV^T\n",
    "                                               \n",
    "Where R is our user ratings matrix, U is the user features matrix, Σ is the diagonal matrix of singular values and V^T is the movie features matrix. U and V^T are orthogonal, U represents how much users ‘like’ each feature and V^T represents how relevant each feature is to a movie. To get the lower rank approximation, I use the matrices and keep only the top k features, which are the k most relevant taste and preference vectors.\n",
    "My objective with this model is to return the movies with the highest predicted rating that a specific user has not yet seen. The reason I have chosen the svds function from scipy is because it allowed me to choose the number of latent factors, and also when using the SVD function from surprise, the result I got back from the algorithms in the competition was half that of the SVDS model, also there is no need to truncate after calculation. \n",
    "\n",
    "# Loading the data\n",
    "I first began by loading all the packages I used and loading all the datasets that were offered in the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "rating_df = pd.read_csv('../data/train-PDA2019.csv',sep=',')\n",
    "rating_df.head()\n",
    "rating_df.head()\n",
    "movies_df = pd.read_csv('../data/content-PDA2019.csv',sep=',')\n",
    "rating_df.head()\n",
    "test = pd.read_csv('../data/test-PDA2019.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the original dataset\n",
    "I pivot the original ratings dataset as to have every usedID on 1 row and every movieID on 1 column. Then we can compute the average rating for each user, then normalize the data by using the average of each user in R_demeaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "itemID  89    93    94    95    97    98    100   101   102   104   ...  3929  \\\nuserID                                                              ...         \n1        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n3        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n5        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   4.0  ...   NaN   \n7        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n9        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n12069    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n12071    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n12073    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n12077    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n12079    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n\nitemID  3930  3931  3932  3937  3938  3945  3946  3950  3952  \nuserID                                                        \n1        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n3        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n5        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n7        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n9        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n...      ...   ...   ...   ...   ...   ...   ...   ...   ...  \n12069    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n12071    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n12073    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n12077    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n12079    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n\n[5690 rows x 1824 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>itemID</th>\n      <th>89</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>97</th>\n      <th>98</th>\n      <th>100</th>\n      <th>101</th>\n      <th>102</th>\n      <th>104</th>\n      <th>...</th>\n      <th>3929</th>\n      <th>3930</th>\n      <th>3931</th>\n      <th>3932</th>\n      <th>3937</th>\n      <th>3938</th>\n      <th>3945</th>\n      <th>3946</th>\n      <th>3950</th>\n      <th>3952</th>\n    </tr>\n    <tr>\n      <th>userID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12069</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12071</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12073</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12077</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12079</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5690 rows × 1824 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 68
    }
   ],
   "source": [
    "r_df = rating_df.pivot(index = 'userID', columns ='itemID', values = 'rating')\n",
    "r_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the mean for each user and demeaning the original data\n",
    "Then we can compute the average rating for each user, then normalize the data by using the average of each user in R_demeaned. We used the pivoted dataset to replace the values for each movies with the average for each user. Doing this we normalize and set the unknown rates with the user mean(0 after substraction). To be able to calculate our 3 matrixes, the data has to be demeaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([4.        , 4.07692308, 4.2972973 , ..., 3.52173913, 4.01190476,\n       3.55744681])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 69
    }
   ],
   "source": [
    "users_mean=np.array(r_df.mean(axis=1))\n",
    "users_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "c:\\users\\abuliga\\pycharmprojects\\thisnewproject\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n  \n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 70
    }
   ],
   "source": [
    "R_demeaned=r_df.sub(r_df.mean(axis=1), axis=0)\n",
    "R_demeaned=R_demeaned.fillna(0).as_matrix()\n",
    "R_demeaned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(5690, 1824)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 84
    }
   ],
   "source": [
    "R_demeaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SVDS to calculate the U,Sigma and V^T matrices\n",
    "Now my matrix is properly formatted and normalized, I can go on with the singular value decomposition. I used the svds function from scipy because it lets me choose how many latent factors I use to approimate the original ratings matrix (instead of having to truncate afterwards). I defined the 3 matrixes above, which will be used to calculate our reconstructed matrix below.\n",
    "For movies, predictions from lower rank matrices with values of k between roughly 20 and 100 have been found to be the best at generalizing to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "U, sigma, Vt = svds(R_demeaned, k = 20,maxiter=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The svds function just prints out the values of the diagonal matrix we defined above as Σ, but for matrix multiplication we need to convert it into a diagonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 42.49678016,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,  42.83402439,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,  43.6471488 ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,  44.31374069,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n         44.52016032,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,  44.803364  ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,  46.71988861,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,  46.9143639 ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n         47.73461868,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,  49.11922517,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,  50.74791535,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,  50.92626449,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n         53.49085039,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,  55.65626106,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,  59.80060071,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,  62.04415555,\n          0.        ,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n         68.06539075,   0.        ,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,  70.22731699,   0.        ,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,  88.23299051,   0.        ],\n       [  0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        , 174.87964375]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 73
    }
   ],
   "source": [
    "sigma = np.diag(sigma)\n",
    "sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need to predict the ratings for all users and all movies in the original dataset. The way the predictions are computed is by using dot product(matrix) and multiplying the U,Σ and then use that dot product to multiplicate again with  the Vt matrix to get the reconstructed matrix. The reconstructed matrix with the the mean of the users gives me back the predicted ratings for each user and for each movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Computing the user predictions\n",
    "Below I obtained all the predicted values for each user that need to be combined with the mean rating of each user. Basically this is the reconstructed A matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "predicted_ratings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now I can add back the user`s means."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_user_predicted_ratings = predicted_ratings+users_mean.reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have all the predicted ratings,I used the columns from the pivoted dataset to match them to the corresponding userID and movieID. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(all_user_predicted_ratings, columns = r_df.columns)\n",
    "preds_df.index=r_df.index.values\n",
    "preds_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the top 10 recommendations for each user\n",
    "In the preds_df dataframe, each column of itemID refers to a movie and each row represents on user. What I did next is sort the ratings in descendig order to get the top 10 predited ratings for each user. Also, I used the userID column from thetest dataset as the index to extract the predictions only for the users in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0           1\n1           3\n2          11\n3          29\n4          31\n        ...  \n1987    12047\n1988    12051\n1989    12061\n1990    12063\n1991    12073\nName: userID, Length: 1992, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 80
    }
   ],
   "source": [
    "users = test.loc[:,'userID']\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I am going to build the recommendations dataset with the following for loop: I used the index above to determine the users that I want to predict for, then I used the top10 list to get the top 10 reccomended movies for each user after sorting them in descending order. Then I transforme the user predictions into a string and concatenated them together in a series where the key value is the userID and the values are the top 10 recommended unseen movies for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "col_names = preds_df.columns\n",
    "ind = 0\n",
    "for j in range(len(users)):\n",
    "    user = users[j]\n",
    "    user_pred = []\n",
    "    rating = preds_df.loc[user,:]\n",
    "    rating = rating.sort_values(ascending=False)\n",
    "    top10 = rating[0:10]\n",
    "    indices = top10.index[:].tolist()\n",
    "    indices_str = str(indices).strip('[]').replace(\",\", \" \")\n",
    "    user_pred = [indices]\n",
    "    test.loc[ind] = pd.Series({'userID':user,'recommended_itemIDs':indices_str})\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here I have the final output where I obtained the top 10 movies for each user and the movies` respective IDs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end I just export my final Series to a csv file as to upload the result to the Kaggle competition page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test.to_csv(path_or_buf = 'recommendations.csv', \n",
    "                  index = False,\n",
    "                  header = True, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}